---
layout: single
title: 简介-CTC
date: 2018-09-15
category: ML
excerpt: 主要介绍CTC的概念
search: true
---

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

# CTC

CTC (Connectionist Temporal Classification) 是针对时间分类任务所设计出来的，利用它可以实现端到端的文本识别，在一定程度上解决了文本识别中的分割问题。  

<img src="/images/CTC/1.png"/> 

通过上面的图片可以对CTC的工作有一个比较直观的理解。它不需要输入输出在每一个时刻都对齐，只要求最后的输出跟目标输出一致。  

CTC与别的算法主要区别在于，他要求输出序列不短于目标序列，且引入了Blank状态。  

如：

$$ F(a-ab-)=F(-aa--abb)=aab $$ 

CTC主要在做的东西是预测每一个时刻的输出，然后合并相邻的重复输出，再移去blank状态。

<img src="/images/CTC/2.png"/> 

这里，两个L之间blank状态有着很关键的作用，它可以分隔开来两个相同的输出，避免了得到helo的结果。  

从上图可以看出，CTC对输出序列有两个要求，第一个是输入序列要不短于label长度;第二个是为了能区分开两个相同字母相邻的情况，需要对label做一下处理，通常的操作是在label中每个元素的前后加上blank状态，这样做会使label长度由U变成2U+1。  

如:  

$$ Z=[ε,y1,εy2,...,ε,yu,ε] $$

# LOSS function

计算前向通道的时候，我们可以采用合并相同路线的方式去简化计算，也就是说每一个节点的概率只计算一次，这样可以减少很多计算量。这类似于HMM的forward-backword Algorithm。

<img src="/images/CTC/3.png"/> 

计算前向通道的时候有一个值得注意的地方，那就是节点链接的合理性  
比如说label集合是[ε1 a ε2 p ε3 p ε4 l ε5 e ε6],ε是blank，为了方便区分加了下  标，假设一个输出序列是正确的话  
如果t时刻预测结果是e，则t-1的预测则一定是[l ε5 e]之间的一个;  
如果 t时刻预测结果是ε6，则t-1的预测则一定是[e ε6]之间的一个;  
如果 t时刻预测结果是p，则t-1的预测则一定是[ε3 p]之间的一个;  
且一条正确的路径只能由[ε1 a]开始，以[e ε6]结束。  

所以前后节点的链接方式如下  

<center class="half">
    <img src="/images/CTC/4.png">  <img src="/images/CTC/5.png">
</center>

下图是一个有效路径的示意图  

 
<img src="/images/CTC/6.png"/> 
  

所以前后向算法在   
前向推导：  
(1)初始化:  

   
<img src="/images/CTC/7.png"/> 
  

(2)递推关系：

   
<img src="/images/CTC/8.png"/> 
  

   
<img src="/images/CTC/9.png"/> 
  

因为时间关系，有些路径不能到达终点 U‘-u-1 > 2(T-t)  

   
<img src="/images/CTC/10.png"/> 
  

同理后向推导：  
(1)初始化:  

<img src="/images/CTC/11.png"/> 
  

(2)递推关系：  

   
<img src="/images/CTC/12.png"/> 
  
   
<img src="/images/CTC/13.png"/> 
  

CTC loss function使用的是最大似然  

取log之后  

   
<img src="/images/CTC/14.png"/> 
  

由前后向算法可得  

   
<img src="/images/CTC/15.png"/> 
  

所以  

   
<img src="/images/CTC/16.png"/> 
  

需要注意的是为了log计算中的underflow问题，可以对log运算进行转化  

   
<img src="/images/CTC/17.png"/> 
  

# Gradient

这里主要参考了[Supervised Sequence Labelling with Recurrent
Neural Networks的第七章第四小节](https://www.cs.toronto.edu/~graves/preprint.pdf)和[CTC学习笔记](https://blog.csdn.net/xmdxcsj/article/details/51763886)  

其中第一份参考资料的式（7.32）应该是错了，多了一个负号。  

   
<img src="/images/CTC/18.png"/> 
  
   
<img src="/images/CTC/19.png"/> 
  
   
<img src="/images/CTC/20.png"/> 
  

计算梯度的过程中，需要注意一点是，如果被求偏导的节点不在当前求偏导的路径上，那么他的倒数为0  

   
<img src="/images/CTC/21.png"/> 
  

在学习CTC的时候，主要是在理解前后向算法，以及推导梯度公式。  
因为它的代码实现比较困难，所以我没有直接运用上述内容进行编程练习，用的只是tensorflow的API，后面有时间的会找一些别人的实现看看，然后再试着自己去实现。  

# cnn_lstm_ctc_HDR

这里写了一个手写数字的识别。问题还比较多，后面会继续完善。  

采用的网络结构是cnn+lstm+ctc  
cnn使用了三层卷积网络和两层全链接层，提取出特征作为lstm的输入。  

使用的数据集参考了  
https://arxiv.org/pdf/1710.03112.pdf  
目前只使用了cvl-strings，里面只有1262张图片。  


编程过程中需要注意的的地方有  

* label数目要计算上blank，即在原来classnum基础上 + 1  
* 注意数据的格式，要符合tensorflow的要求  
* 因为label不定长，需要将其转换成稀疏矩阵  

这是代码的[github仓库](https://github.com/jhl13/cnn_lstm_ctc_HDR/blob/master/rnn.ipynb)

参考资料：  
http://ilovin.me/2017-04-23/tensorflow-lstm-ctc-input-output/  
http://ilovin.me/2017-04-06/tensorflow-lstm-ctc-ocr/  
https://github.com/xiaofengShi/CTC_TF/blob/padding_warpctc/lib/networks/network.py  
https://github.com/jimmyleaf/ocr_tensorflow_cnn  

